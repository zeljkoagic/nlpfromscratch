{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from dependency_decoding import chu_liu_edmonds\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent = np.load(\"en.1.npz\")\n",
    "T_proj = sent['projection_tensor']\n",
    "source_langs = sent['source_languages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def count_correct(pred_heads, gold_heads):\n",
    "    assert len(pred_heads) == len(gold_heads)\n",
    "    # Do not count the root attachment at index 0 as correct\n",
    "    return sum(pred == gold for pred, gold in zip(pred_heads, gold_heads)) - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.814724</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.447473e-05</td>\n",
       "      <td>0.900435</td>\n",
       "      <td>0.192033</td>\n",
       "      <td>0.420597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.105496</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.411754e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000261</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>4.620701e-05</td>\n",
       "      <td>0.440397</td>\n",
       "      <td>0.093922</td>\n",
       "      <td>0.205711</td>\n",
       "      <td>9.148190e-09</td>\n",
       "      <td>0.051597</td>\n",
       "      <td>-0.000150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>1.668668e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.483845</td>\n",
       "      <td>0.251571</td>\n",
       "      <td>1.230419e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.077179</td>\n",
       "      <td>1.251440</td>\n",
       "      <td>8.719103e-05</td>\n",
       "      <td>0.384532</td>\n",
       "      <td>-1.433711</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.338229</td>\n",
       "      <td>2.467738e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.001916</td>\n",
       "      <td>-0.273783</td>\n",
       "      <td>-2.026755e-05</td>\n",
       "      <td>-0.193169</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.067544</td>\n",
       "      <td>-9.488932e-05</td>\n",
       "      <td>0.911320</td>\n",
       "      <td>-1.235253</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.219997</td>\n",
       "      <td>-2.685620e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.429096</td>\n",
       "      <td>-0.022297</td>\n",
       "      <td>-2.962642e-05</td>\n",
       "      <td>-0.282368</td>\n",
       "      <td>0.182370</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.727927e-06</td>\n",
       "      <td>0.512244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.424536</td>\n",
       "      <td>3.240084e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.000629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.274361e-08</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.182466e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.502256</td>\n",
       "      <td>-0.363040</td>\n",
       "      <td>-4.669691e-05</td>\n",
       "      <td>-0.445066</td>\n",
       "      <td>0.753000</td>\n",
       "      <td>1.101405</td>\n",
       "      <td>-1.258244e-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.909588</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.167354</td>\n",
       "      <td>1.337820e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.290791</td>\n",
       "      <td>1.728895e-06</td>\n",
       "      <td>0.016478</td>\n",
       "      <td>1.099066</td>\n",
       "      <td>0.409479</td>\n",
       "      <td>-1.007841e-04</td>\n",
       "      <td>1.838423</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.246433</td>\n",
       "      <td>1.952661e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1.555405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.571981e-05</td>\n",
       "      <td>-0.245134</td>\n",
       "      <td>1.006486</td>\n",
       "      <td>0.561960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.762564</td>\n",
       "      <td>-0.509270</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.788178e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.001780</td>\n",
       "      <td>-0.000486</td>\n",
       "      <td>9.267312e-08</td>\n",
       "      <td>0.000883</td>\n",
       "      <td>0.002491</td>\n",
       "      <td>0.001897</td>\n",
       "      <td>-1.685855e-07</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>-0.002195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>4.425775e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1             2         3         4         5   \\\n",
       "0        NaN       NaN           NaN       NaN       NaN       NaN   \n",
       "1  -1.814724       NaN  9.447473e-05  0.900435  0.192033  0.420597   \n",
       "2  -0.000261  0.000026  4.620701e-05  0.440397  0.093922  0.205711   \n",
       "3  -2.483845  0.251571  1.230419e-01       NaN  0.077179  1.251440   \n",
       "4  -2.001916 -0.273783 -2.026755e-05 -0.193169       NaN  1.067544   \n",
       "5  -0.429096 -0.022297 -2.962642e-05 -0.282368  0.182370       NaN   \n",
       "6  -0.000629       NaN  3.274361e-08  0.000312  0.000067  0.000146   \n",
       "7  -1.502256 -0.363040 -4.669691e-05 -0.445066  0.753000  1.101405   \n",
       "8        NaN -0.290791  1.728895e-06  0.016478  1.099066  0.409479   \n",
       "9        NaN       NaN           NaN       NaN       NaN       NaN   \n",
       "10 -1.555405       NaN -2.571981e-05 -0.245134  1.006486  0.561960   \n",
       "11 -0.001780 -0.000486  9.267312e-08  0.000883  0.002491  0.001897   \n",
       "\n",
       "              6         7         8   9         10            11  \n",
       "0            NaN       NaN       NaN NaN       NaN           NaN  \n",
       "1            NaN  0.105496       NaN NaN       NaN  3.411754e-04  \n",
       "2   9.148190e-09  0.051597 -0.000150 NaN -0.000035  1.668668e-04  \n",
       "3   8.719103e-05  0.384532 -1.433711 NaN -0.338229  2.467738e-04  \n",
       "4  -9.488932e-05  0.911320 -1.235253 NaN -0.219997 -2.685620e-04  \n",
       "5  -7.727927e-06  0.512244       NaN NaN -0.424536  3.240084e-04  \n",
       "6            NaN  0.000037       NaN NaN       NaN  1.182466e-07  \n",
       "7  -1.258244e-04       NaN -0.909588 NaN -0.167354  1.337820e-03  \n",
       "8  -1.007841e-04  1.838423       NaN NaN  0.246433  1.952661e-03  \n",
       "9            NaN       NaN       NaN NaN       NaN           NaN  \n",
       "10           NaN  1.762564 -0.509270 NaN       NaN  1.788178e-03  \n",
       "11 -1.685855e-07  0.004167 -0.002195 NaN  0.000559  4.425775e-06  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_root_row(T):\n",
    "    first_row = np.zeros([1, T.shape[1], T.shape[2]]) * np.nan\n",
    "    return np.vstack([first_row, T])\n",
    "    \n",
    "T_proj = add_root_row(T_proj)\n",
    "T_proj_de = T_proj[:,:,4]\n",
    "\n",
    "\n",
    "\n",
    "D = pd.DataFrame(T_proj_de)\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.4838451914699999"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmin(T_proj_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, 3, 0, 5, 5, 6, 0, 5, 7, 0, 7, 7] [-1  3  3  4  5  0  7  5  7 10  7  5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_proj_de[2] = np.nanmin(T_proj_de)\n",
    "T_proj_de[6] = np.nanmin(T_proj_de)\n",
    "T_proj_de[9] = np.nanmin(T_proj_de)\n",
    "\n",
    "pred_heads, tree_score = chu_liu_edmonds(T_proj_de)\n",
    "gold_heads = np.concatenate([[-1], sent[\"heads\"]])\n",
    "print(pred_heads, gold_heads)\n",
    "count_correct(pred_heads, gold_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3032\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>tree_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all_max</th>\n",
       "      <td>1470</td>\n",
       "      <td>1268.146667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all_mean</th>\n",
       "      <td>1752</td>\n",
       "      <td>403.579912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all_mean_softmax</th>\n",
       "      <td>1753</td>\n",
       "      <td>203.886650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all_sum</th>\n",
       "      <td>1743</td>\n",
       "      <td>7436.237583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all_sum_l1</th>\n",
       "      <td>1743</td>\n",
       "      <td>391.108592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all_sum_softmax</th>\n",
       "      <td>1754</td>\n",
       "      <td>693.475312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ar</th>\n",
       "      <td>693</td>\n",
       "      <td>411.095047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bg</th>\n",
       "      <td>1091</td>\n",
       "      <td>602.754560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs</th>\n",
       "      <td>842</td>\n",
       "      <td>441.904718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>da</th>\n",
       "      <td>933</td>\n",
       "      <td>486.329076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de</th>\n",
       "      <td>1130</td>\n",
       "      <td>622.250292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es</th>\n",
       "      <td>1131</td>\n",
       "      <td>688.950741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eu</th>\n",
       "      <td>347</td>\n",
       "      <td>227.522313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fa</th>\n",
       "      <td>669</td>\n",
       "      <td>388.692828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fi</th>\n",
       "      <td>698</td>\n",
       "      <td>366.395960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>875</td>\n",
       "      <td>616.411513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>he</th>\n",
       "      <td>672</td>\n",
       "      <td>346.168910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hi</th>\n",
       "      <td>804</td>\n",
       "      <td>408.241620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hr</th>\n",
       "      <td>837</td>\n",
       "      <td>471.394359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>549</td>\n",
       "      <td>284.813292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>1093</td>\n",
       "      <td>564.793057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>1023</td>\n",
       "      <td>596.053379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pl</th>\n",
       "      <td>917</td>\n",
       "      <td>491.214660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt</th>\n",
       "      <td>882</td>\n",
       "      <td>628.622682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sl</th>\n",
       "      <td>969</td>\n",
       "      <td>550.488765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv</th>\n",
       "      <td>1084</td>\n",
       "      <td>559.952044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  accuracy   tree_score\n",
       "all_max               1470  1268.146667\n",
       "all_mean              1752   403.579912\n",
       "all_mean_softmax      1753   203.886650\n",
       "all_sum               1743  7436.237583\n",
       "all_sum_l1            1743   391.108592\n",
       "all_sum_softmax       1754   693.475312\n",
       "ar                     693   411.095047\n",
       "bg                    1091   602.754560\n",
       "cs                     842   441.904718\n",
       "da                     933   486.329076\n",
       "de                    1130   622.250292\n",
       "es                    1131   688.950741\n",
       "eu                     347   227.522313\n",
       "fa                     669   388.692828\n",
       "fi                     698   366.395960\n",
       "fr                     875   616.411513\n",
       "he                     672   346.168910\n",
       "hi                     804   408.241620\n",
       "hr                     837   471.394359\n",
       "id                     549   284.813292\n",
       "it                    1093   564.793057\n",
       "no                    1023   596.053379\n",
       "pl                     917   491.214660\n",
       "pt                     882   628.622682\n",
       "sl                     969   550.488765\n",
       "sv                    1084   559.952044"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import warnings\n",
    "#warnings.filterwarnings('ignore', r\"\")\n",
    "\n",
    "p = Path(\".\")\n",
    "scores = defaultdict(list)\n",
    "sent_lens = []\n",
    "tree_scores = defaultdict(list)\n",
    "\n",
    "def softmax(sentence_matrix, temperature=1.0):\n",
    "    m_exp = np.exp(sentence_matrix/temperature)\n",
    "    return (m_exp.T / np.nansum(m_exp, axis=1)).T\n",
    "\n",
    "def l1_normalize(M):\n",
    "    return (M.T / np.nansum(M, axis=1)).T\n",
    "\n",
    "def eliminate_all_nan_rows(M_proj):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        by_row = np.nanmax(M_proj, axis=1)\n",
    "        all_nan_rows = np.isnan(by_row)\n",
    "        M_proj[all_nan_rows] = np.nanmin(M_proj)\n",
    "\n",
    "def eval_projection(M_proj, name):\n",
    "    eliminate_all_nan_rows(M_proj)\n",
    "    pred_heads_from_all, tree_score = chu_liu_edmonds(M_proj)\n",
    "    scores[name].append(count_correct(pred_heads_from_all, gold_heads))\n",
    "    tree_scores[name].append(tree_score)\n",
    "\n",
    "def apply_softmax_per_row_per_lang(T_proj):\n",
    "    for lang in range(T_proj.shape[2]):\n",
    "        T_proj_lang = T_proj[:,:,lang]\n",
    "        T_proj[:,:,lang] = softmax(T_proj_lang, temperature=1)\n",
    "    \n",
    "token_count = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for file in p.glob(\"*.npz\"):\n",
    "    sent = np.load(str(file))\n",
    "    T_proj = sent['projection_tensor']\n",
    "    \n",
    "    #print(T_proj.shape[2])\n",
    "    #if T_proj.shape[2] < 15:\n",
    "    #    print(T_proj.shape[2])\n",
    "    #    continue\n",
    "    \n",
    "    source_langs = sent['source_languages']\n",
    "    T_proj = add_root_row(T_proj)\n",
    "    \n",
    "    apply_softmax_per_row_per_lang(T_proj)\n",
    "    \n",
    "    gold_heads = np.concatenate([[-1], sent[\"heads\"]])\n",
    "    for lang in range(T_proj.shape[2]):\n",
    "        lang_name = source_langs[lang]\n",
    "        \n",
    "        T_proj_lang = T_proj[:,:,lang]\n",
    "        T_proj_lang = np.where(np.isnan(T_proj_lang), np.nanmin(T_proj_lang), T_proj_lang)\n",
    "        pred_heads, tree_score = chu_liu_edmonds(T_proj_lang)\n",
    "        \n",
    "        scores[lang_name].append(count_correct(pred_heads, gold_heads))\n",
    "        tree_scores[lang_name].append(tree_score)\n",
    "        \n",
    "        \n",
    "    # Aggregate measures\n",
    "    good_lang_ids = [i for i, lang_name in enumerate(source_langs)\n",
    "                     if lang_name in [\"fr\", \"de\", \"es\", \"sv\", \"no\", \"da\"]]\n",
    "    \n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        eval_projection(np.nansum(T_proj, axis=2), \"all_sum\")\n",
    "        eval_projection(np.nanmean(T_proj, axis=2), \"all_mean\")\n",
    "        eval_projection(np.nanmax(T_proj, axis=2), \"all_max\")\n",
    "\n",
    "        eval_projection(softmax(np.nansum(T_proj, axis=2)), \"all_sum_softmax\")\n",
    "        eval_projection(softmax(np.nanmean(T_proj, axis=2)), \"all_mean_softmax\")\n",
    "\n",
    "        eval_projection(l1_normalize(np.nansum(T_proj, axis=2)), \"all_sum_l1\")\n",
    "    \n",
    "    \n",
    "    sent_lens.append(len(pred_heads) - 1)\n",
    "    token_count += len(pred_heads) - 1\n",
    "\n",
    "aggregated_scores = {k: sum(vals) for k, vals in scores.items()}\n",
    "aggregated_tree_scores = {k: np.nansum(vals) for k, vals in tree_scores.items()}\n",
    "print(token_count)\n",
    "pd.DataFrame({\"tree_score\": pd.Series(aggregated_tree_scores), \n",
    "              \"accuracy\": pd.Series(aggregated_scores)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10da83080>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAECCAYAAAAMxDf2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c0a0e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "D = pd.DataFrame({\"accuracy\": np.array(scores[\"all_sum\"])  / np.array(sent_lens), \n",
    "                  \"tree_score\": np.array(tree_scores[\"all_sum\"]),\n",
    "                  \"norm_tree_score\": np.array(tree_scores[\"all_sum\"]) / np.array(sent_lens),\n",
    "                  \"sent_lens\": np.array(sent_lens)}\n",
    "                )\n",
    "\n",
    "#for i in range(11):\n",
    "#    print(D[D.accuracy > i / 10].sent_lens.mean())\n",
    "\n",
    "D.sent_lens.hist(bins=25)\n",
    "#D[D.sent_lens > 35].accuracy.mean()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  3,  0,  5,  3,  3,  3,  3, 10,  3, 12, 10, 10, 10,  3, 17, 15,\n",
       "       17,  3, 21, 15, 23,  3, 26, 27, 27, 23, 27, 30, 27, 33, 33, 30, 37,\n",
       "       37, 37, 27,  3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent['heads']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Score matrix must be square",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d8ed125610ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mM_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM_norm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mchu_liu_edmonds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mdependency_decoding.pyx\u001b[0m in \u001b[0;36mdependency_decoding.chu_liu_edmonds (dependency_decoding.cpp:1552)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Score matrix must be square"
     ]
    }
   ],
   "source": [
    "x = np.zeros(M_norm.shape[1]) * np.nan\n",
    "M_norm = np.vstack([x, M_norm])\n",
    "chu_liu_edmonds(M_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
