{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from dependency_decoding import chu_liu_edmonds\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent = np.load(\"en.1.npz\")\n",
    "T_proj = sent['projection_tensor']\n",
    "source_langs = sent['source_languages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def count_correct(pred_heads, gold_heads):\n",
    "    assert len(pred_heads) == len(gold_heads)\n",
    "    # Do not count the root attachment at index 0 as correct\n",
    "    return sum(pred == gold for pred, gold in zip(pred_heads, gold_heads)) - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.704729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.342184</td>\n",
       "      <td>0.286721</td>\n",
       "      <td>0.626874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.157235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.484111</td>\n",
       "      <td>0.374991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.077324</td>\n",
       "      <td>1.251576</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.384573</td>\n",
       "      <td>-1.437115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.338265</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.005476</td>\n",
       "      <td>-0.408782</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.193533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.069444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.912941</td>\n",
       "      <td>-1.240255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.220388</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.429097</td>\n",
       "      <td>-0.033233</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.282399</td>\n",
       "      <td>0.182695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.512245</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.424537</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.502257</td>\n",
       "      <td>-0.541087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.445114</td>\n",
       "      <td>0.754339</td>\n",
       "      <td>1.101407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.911649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.167354</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.434388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016517</td>\n",
       "      <td>1.103517</td>\n",
       "      <td>0.410408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.842590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.246992</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1.555405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.245161</td>\n",
       "      <td>1.008276</td>\n",
       "      <td>0.561961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.762564</td>\n",
       "      <td>-0.510424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.211470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.554924</td>\n",
       "      <td>0.728259</td>\n",
       "      <td>1.756062</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.988084</td>\n",
       "      <td>-0.291733</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.113105</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1   2         3         4         5   6         7   \\\n",
       "0        NaN       NaN NaN       NaN       NaN       NaN NaN       NaN   \n",
       "1  -2.704729       NaN NaN  1.342184  0.286721  0.626874 NaN  0.157235   \n",
       "2        NaN       NaN NaN       NaN       NaN       NaN NaN       NaN   \n",
       "3  -2.484111  0.374991 NaN       NaN  0.077324  1.251576 NaN  0.384573   \n",
       "4  -2.005476 -0.408782 NaN -0.193533       NaN  1.069444 NaN  0.912941   \n",
       "5  -0.429097 -0.033233 NaN -0.282399  0.182695       NaN NaN  0.512245   \n",
       "6        NaN       NaN NaN       NaN       NaN       NaN NaN       NaN   \n",
       "7  -1.502257 -0.541087 NaN -0.445114  0.754339  1.101407 NaN       NaN   \n",
       "8        NaN -0.434388 NaN  0.016517  1.103517  0.410408 NaN  1.842590   \n",
       "9        NaN       NaN NaN       NaN       NaN       NaN NaN       NaN   \n",
       "10 -1.555405       NaN NaN -0.245161  1.008276  0.561961 NaN  1.762564   \n",
       "11       NaN -0.211470 NaN -0.554924  0.728259  1.756062 NaN  0.988084   \n",
       "\n",
       "          8   9         10  11  \n",
       "0        NaN NaN       NaN NaN  \n",
       "1        NaN NaN       NaN NaN  \n",
       "2        NaN NaN       NaN NaN  \n",
       "3  -1.437115 NaN -0.338265 NaN  \n",
       "4  -1.240255 NaN -0.220388 NaN  \n",
       "5        NaN NaN -0.424537 NaN  \n",
       "6        NaN NaN       NaN NaN  \n",
       "7  -0.911649 NaN -0.167354 NaN  \n",
       "8        NaN NaN  0.246992 NaN  \n",
       "9        NaN NaN       NaN NaN  \n",
       "10 -0.510424 NaN       NaN NaN  \n",
       "11 -0.291733 NaN  0.113105 NaN  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_root_row(T):\n",
    "    first_row = np.zeros([1, T.shape[1], T.shape[2]]) * np.nan\n",
    "    return np.vstack([first_row, T])\n",
    "    \n",
    "T_proj = add_root_row(T_proj)\n",
    "T_proj_de = T_proj[:,:,4]\n",
    "\n",
    "\n",
    "\n",
    "D = pd.DataFrame(T_proj_de)\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.7047291972199998"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmin(T_proj_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, 3, 0, 5, 5, 0, 0, 5, 7, 0, 7, 5] [-1  3  3  4  5  0  7  5  7 10  7  5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_proj_de[2] = np.nanmin(T_proj_de)\n",
    "T_proj_de[6] = np.nanmin(T_proj_de)\n",
    "T_proj_de[9] = np.nanmin(T_proj_de)\n",
    "\n",
    "pred_heads, tree_score = chu_liu_edmonds(T_proj_de)\n",
    "gold_heads = np.concatenate([[-1], sent[\"heads\"]])\n",
    "print(pred_heads, gold_heads)\n",
    "count_correct(pred_heads, gold_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130189\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>tree_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all_max</th>\n",
       "      <td>54345</td>\n",
       "      <td>81014.513052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all_mean</th>\n",
       "      <td>63511</td>\n",
       "      <td>46358.976551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all_mean_softmax</th>\n",
       "      <td>63488</td>\n",
       "      <td>8184.944440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all_sum</th>\n",
       "      <td>71133</td>\n",
       "      <td>404873.953461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all_sum_l1</th>\n",
       "      <td>70594</td>\n",
       "      <td>34602.708497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all_sum_softmax</th>\n",
       "      <td>70758</td>\n",
       "      <td>44431.888222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ar</th>\n",
       "      <td>17655</td>\n",
       "      <td>21177.412375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bg</th>\n",
       "      <td>37863</td>\n",
       "      <td>35625.761481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs</th>\n",
       "      <td>30762</td>\n",
       "      <td>28161.212248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>da</th>\n",
       "      <td>33953</td>\n",
       "      <td>32570.295003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de</th>\n",
       "      <td>41132</td>\n",
       "      <td>35092.846477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es</th>\n",
       "      <td>42021</td>\n",
       "      <td>35127.566288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eu</th>\n",
       "      <td>11162</td>\n",
       "      <td>17930.231097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fa</th>\n",
       "      <td>26668</td>\n",
       "      <td>28008.903638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fi</th>\n",
       "      <td>27713</td>\n",
       "      <td>25847.744885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>42073</td>\n",
       "      <td>35654.734145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>he</th>\n",
       "      <td>18879</td>\n",
       "      <td>20105.740818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hi</th>\n",
       "      <td>22671</td>\n",
       "      <td>32936.733746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hr</th>\n",
       "      <td>25237</td>\n",
       "      <td>30327.962347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>16989</td>\n",
       "      <td>23567.423134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>34906</td>\n",
       "      <td>32273.562345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>42198</td>\n",
       "      <td>35859.130509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pl</th>\n",
       "      <td>32761</td>\n",
       "      <td>30534.345520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt</th>\n",
       "      <td>37964</td>\n",
       "      <td>33193.118133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sl</th>\n",
       "      <td>32850</td>\n",
       "      <td>33909.049250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv</th>\n",
       "      <td>38305</td>\n",
       "      <td>35084.107832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  accuracy     tree_score\n",
       "all_max              54345   81014.513052\n",
       "all_mean             63511   46358.976551\n",
       "all_mean_softmax     63488    8184.944440\n",
       "all_sum              71133  404873.953461\n",
       "all_sum_l1           70594   34602.708497\n",
       "all_sum_softmax      70758   44431.888222\n",
       "ar                   17655   21177.412375\n",
       "bg                   37863   35625.761481\n",
       "cs                   30762   28161.212248\n",
       "da                   33953   32570.295003\n",
       "de                   41132   35092.846477\n",
       "es                   42021   35127.566288\n",
       "eu                   11162   17930.231097\n",
       "fa                   26668   28008.903638\n",
       "fi                   27713   25847.744885\n",
       "fr                   42073   35654.734145\n",
       "he                   18879   20105.740818\n",
       "hi                   22671   32936.733746\n",
       "hr                   25237   30327.962347\n",
       "id                   16989   23567.423134\n",
       "it                   34906   32273.562345\n",
       "no                   42198   35859.130509\n",
       "pl                   32761   30534.345520\n",
       "pt                   37964   33193.118133\n",
       "sl                   32850   33909.049250\n",
       "sv                   38305   35084.107832"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import warnings\n",
    "#warnings.filterwarnings('ignore', r\"\")\n",
    "\n",
    "p = Path(\".\")\n",
    "scores = defaultdict(list)\n",
    "sent_lens = []\n",
    "tree_scores = defaultdict(list)\n",
    "\n",
    "def softmax(sentence_matrix, temperature=1.0):\n",
    "    m_exp = np.exp(sentence_matrix/temperature)\n",
    "    return (m_exp.T / np.nansum(m_exp, axis=1)).T\n",
    "\n",
    "def l1_normalize(M):\n",
    "    return (M.T / np.nansum(M, axis=1)).T\n",
    "\n",
    "def eliminate_all_nan_rows(M_proj):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        by_row = np.nanmax(M_proj, axis=1)\n",
    "        all_nan_rows = np.isnan(by_row)\n",
    "        M_proj[all_nan_rows] = np.nanmin(M_proj)\n",
    "\n",
    "def eval_projection(M_proj, name):\n",
    "    eliminate_all_nan_rows(M_proj)\n",
    "    pred_heads_from_all, tree_score = chu_liu_edmonds(M_proj)\n",
    "    scores[name].append(count_correct(pred_heads_from_all, gold_heads))\n",
    "    tree_scores[name].append(tree_score)\n",
    "\n",
    "def apply_softmax_per_row_per_lang(T_proj):\n",
    "    for lang in range(T_proj.shape[2]):\n",
    "        T_proj_lang = T_proj[:,:,lang]\n",
    "        T_proj[:,:,lang] = softmax(T_proj_lang, temperature=1)\n",
    "    \n",
    "token_count = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for file in p.glob(\"*.npz\"):\n",
    "    sent = np.load(str(file))\n",
    "    T_proj = sent['projection_tensor']\n",
    "    \n",
    "    #print(T_proj.shape[2])\n",
    "    #if T_proj.shape[2] < 15:\n",
    "    #    print(T_proj.shape[2])\n",
    "    #    continue\n",
    "    \n",
    "    source_langs = sent['source_languages']\n",
    "    T_proj = add_root_row(T_proj)\n",
    "    \n",
    "    apply_softmax_per_row_per_lang(T_proj)\n",
    "    \n",
    "    gold_heads = np.concatenate([[-1], sent[\"heads\"]])\n",
    "    for lang in range(T_proj.shape[2]):\n",
    "        lang_name = source_langs[lang]\n",
    "        \n",
    "        T_proj_lang = T_proj[:,:,lang]\n",
    "        T_proj_lang = np.where(np.isnan(T_proj_lang), np.nanmin(T_proj_lang), T_proj_lang)\n",
    "        pred_heads, tree_score = chu_liu_edmonds(T_proj_lang)\n",
    "        \n",
    "        scores[lang_name].append(count_correct(pred_heads, gold_heads))\n",
    "        tree_scores[lang_name].append(tree_score)\n",
    "        \n",
    "        \n",
    "    # Aggregate measures\n",
    "    good_lang_ids = [i for i, lang_name in enumerate(source_langs)\n",
    "                     if lang_name in [\"fr\", \"de\", \"es\", \"sv\", \"no\", \"da\"]]\n",
    "    \n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        eval_projection(np.nansum(T_proj, axis=2), \"all_sum\")\n",
    "        eval_projection(np.nanmean(T_proj, axis=2), \"all_mean\")\n",
    "        eval_projection(np.nanmax(T_proj, axis=2), \"all_max\")\n",
    "\n",
    "        eval_projection(softmax(np.nansum(T_proj, axis=2)), \"all_sum_softmax\")\n",
    "        eval_projection(softmax(np.nanmean(T_proj, axis=2)), \"all_mean_softmax\")\n",
    "\n",
    "        eval_projection(l1_normalize(np.nansum(T_proj, axis=2)), \"all_sum_l1\")\n",
    "    \n",
    "    \n",
    "    sent_lens.append(len(pred_heads) - 1)\n",
    "    token_count += len(pred_heads) - 1\n",
    "\n",
    "aggregated_scores = {k: sum(vals) for k, vals in scores.items()}\n",
    "aggregated_tree_scores = {k: np.nansum(vals) for k, vals in tree_scores.items()}\n",
    "print(token_count)\n",
    "pd.DataFrame({\"tree_score\": pd.Series(aggregated_tree_scores), \n",
    "              \"accuracy\": pd.Series(aggregated_scores)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10da83080>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAECCAYAAAAMxDf2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c0a0e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "D = pd.DataFrame({\"accuracy\": np.array(scores[\"all_sum\"])  / np.array(sent_lens), \n",
    "                  \"tree_score\": np.array(tree_scores[\"all_sum\"]),\n",
    "                  \"norm_tree_score\": np.array(tree_scores[\"all_sum\"]) / np.array(sent_lens),\n",
    "                  \"sent_lens\": np.array(sent_lens)}\n",
    "                )\n",
    "\n",
    "#for i in range(11):\n",
    "#    print(D[D.accuracy > i / 10].sent_lens.mean())\n",
    "\n",
    "D.sent_lens.hist(bins=25)\n",
    "#D[D.sent_lens > 35].accuracy.mean()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  3,  0,  5,  3,  3,  3,  3, 10,  3, 12, 10, 10, 10,  3, 17, 15,\n",
       "       17,  3, 21, 15, 23,  3, 26, 27, 27, 23, 27, 30, 27, 33, 33, 30, 37,\n",
       "       37, 37, 27,  3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent['heads']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Score matrix must be square",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d8ed125610ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mM_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM_norm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mchu_liu_edmonds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mdependency_decoding.pyx\u001b[0m in \u001b[0;36mdependency_decoding.chu_liu_edmonds (dependency_decoding.cpp:1552)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Score matrix must be square"
     ]
    }
   ],
   "source": [
    "x = np.zeros(M_norm.shape[1]) * np.nan\n",
    "M_norm = np.vstack([x, M_norm])\n",
    "chu_liu_edmonds(M_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
