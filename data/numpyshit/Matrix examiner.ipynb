{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from dependency_decoding import chu_liu_edmonds\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent = np.load(\"en.1.npz\")\n",
    "T_proj = sent['projection_tensor']\n",
    "source_langs = sent['source_languages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def count_correct(pred_heads, gold_heads):\n",
    "    assert len(pred_heads) == len(gold_heads)\n",
    "    # Do not count the root attachment at index 0 as correct\n",
    "    return sum(pred == gold for pred, gold in zip(pred_heads, gold_heads)) - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8.62632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.65635</td>\n",
       "      <td>2.938030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.046870</td>\n",
       "      <td>0.814859</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.47144</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.473582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.027130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.860477</td>\n",
       "      <td>1.450960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.227550</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-7.83572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.205030</td>\n",
       "      <td>2.77568</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671676</td>\n",
       "      <td>1.222200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.041870</td>\n",
       "      <td>-0.072970</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-6.12050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.199320</td>\n",
       "      <td>2.44934</td>\n",
       "      <td>0.186358</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.168920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.689140</td>\n",
       "      <td>0.138240</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-4.31718</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.436383</td>\n",
       "      <td>2.50661</td>\n",
       "      <td>-0.264420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.884740</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.100350</td>\n",
       "      <td>0.233265</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.245201</td>\n",
       "      <td>1.26849</td>\n",
       "      <td>0.562723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.510390</td>\n",
       "      <td>3.834650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.975684</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-4.50764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.54004</td>\n",
       "      <td>0.093853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.339740</td>\n",
       "      <td>3.691260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.381441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0   1         2        3         4   5         6         7   8   \\\n",
       "0       NaN NaN       NaN      NaN       NaN NaN       NaN       NaN NaN   \n",
       "1       NaN NaN       NaN      NaN       NaN NaN       NaN       NaN NaN   \n",
       "2  -8.62632 NaN       NaN  1.65635  2.938030 NaN  1.046870  0.814859 NaN   \n",
       "3  -0.47144 NaN  0.473582      NaN  0.027130 NaN  0.860477  1.450960 NaN   \n",
       "4  -7.83572 NaN  1.205030  2.77568       NaN NaN  0.671676  1.222200 NaN   \n",
       "5       NaN NaN       NaN      NaN       NaN NaN       NaN       NaN NaN   \n",
       "6  -6.12050 NaN -0.199320  2.44934  0.186358 NaN       NaN  2.168920 NaN   \n",
       "7  -4.31718 NaN -0.436383  2.50661 -0.264420 NaN  1.884740       NaN NaN   \n",
       "8       NaN NaN       NaN      NaN       NaN NaN       NaN       NaN NaN   \n",
       "9       NaN NaN -0.245201  1.26849  0.562723 NaN  2.510390  3.834650 NaN   \n",
       "10 -4.50764 NaN       NaN  1.54004  0.093853 NaN  2.339740  3.691260 NaN   \n",
       "11      NaN NaN       NaN      NaN       NaN NaN       NaN       NaN NaN   \n",
       "\n",
       "          9         10  11  \n",
       "0        NaN       NaN NaN  \n",
       "1        NaN       NaN NaN  \n",
       "2        NaN       NaN NaN  \n",
       "3        NaN -0.227550 NaN  \n",
       "4  -2.041870 -0.072970 NaN  \n",
       "5        NaN       NaN NaN  \n",
       "6  -1.689140  0.138240 NaN  \n",
       "7  -1.100350  0.233265 NaN  \n",
       "8        NaN       NaN NaN  \n",
       "9        NaN  0.975684 NaN  \n",
       "10 -0.381441       NaN NaN  \n",
       "11       NaN       NaN NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_proj_de = T_proj[:,:,4]\n",
    "\n",
    "\n",
    "\n",
    "D = pd.DataFrame(T_proj_de)\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.6263199999999998"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmin(T_proj_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, 0, 0, 6, 3, 0, 0, 3, 0, 0, 7, 0] [-1  3  3  4  5  0  7  5  7 10  7  5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_proj_de[2] = np.nanmin(T_proj_de)\n",
    "T_proj_de[6] = np.nanmin(T_proj_de)\n",
    "T_proj_de[9] = np.nanmin(T_proj_de)\n",
    "\n",
    "pred_heads, tree_score = chu_liu_edmonds(T_proj_de)\n",
    "gold_heads = np.concatenate([[-1], sent[\"heads\"]])\n",
    "print(pred_heads, gold_heads)\n",
    "count_correct(pred_heads, gold_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zagic/anaconda/lib/python3.4/site-packages/numpy/lib/nanfunctions.py:227: RuntimeWarning: All-NaN axis encountered\n",
      "  warnings.warn(\"All-NaN axis encountered\", RuntimeWarning)\n",
      "/Users/zagic/anaconda/lib/python3.4/site-packages/numpy/lib/nanfunctions.py:227: RuntimeWarning: All-NaN axis encountered\n",
      "  warnings.warn(\"All-NaN axis encountered\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23686\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>tree_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all_max</th>\n",
       "      <td>6526</td>\n",
       "      <td>1.703283e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all_mean</th>\n",
       "      <td>7870</td>\n",
       "      <td>1.015316e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all_mean_softmax</th>\n",
       "      <td>7829</td>\n",
       "      <td>1.876890e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all_sum</th>\n",
       "      <td>8494</td>\n",
       "      <td>5.313474e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all_sum_l1</th>\n",
       "      <td>8357</td>\n",
       "      <td>6.197521e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all_sum_softmax</th>\n",
       "      <td>8483</td>\n",
       "      <td>5.940104e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ar</th>\n",
       "      <td>188</td>\n",
       "      <td>3.948098e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bg</th>\n",
       "      <td>4200</td>\n",
       "      <td>8.150486e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs</th>\n",
       "      <td>2678</td>\n",
       "      <td>5.502139e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>da</th>\n",
       "      <td>3542</td>\n",
       "      <td>5.023820e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de</th>\n",
       "      <td>3132</td>\n",
       "      <td>5.543252e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es</th>\n",
       "      <td>2709</td>\n",
       "      <td>3.969974e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eu</th>\n",
       "      <td>950</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fa</th>\n",
       "      <td>1381</td>\n",
       "      <td>4.141576e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fi</th>\n",
       "      <td>2319</td>\n",
       "      <td>3.912588e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>4528</td>\n",
       "      <td>6.260868e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>he</th>\n",
       "      <td>1149</td>\n",
       "      <td>3.234239e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hi</th>\n",
       "      <td>2470</td>\n",
       "      <td>8.541007e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hr</th>\n",
       "      <td>1883</td>\n",
       "      <td>3.378965e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>846</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>3819</td>\n",
       "      <td>6.343649e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>4596</td>\n",
       "      <td>6.609295e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pl</th>\n",
       "      <td>3012</td>\n",
       "      <td>6.186098e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt</th>\n",
       "      <td>4838</td>\n",
       "      <td>7.715885e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sl</th>\n",
       "      <td>3129</td>\n",
       "      <td>6.347211e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv</th>\n",
       "      <td>3910</td>\n",
       "      <td>5.230097e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  accuracy    tree_score\n",
       "all_max               6526  1.703283e+04\n",
       "all_mean              7870  1.015316e+04\n",
       "all_mean_softmax      7829  1.876890e+03\n",
       "all_sum               8494  5.313474e+04\n",
       "all_sum_l1            8357  6.197521e+03\n",
       "all_sum_softmax       8483  5.940104e+03\n",
       "ar                     188  3.948098e+02\n",
       "bg                    4200  8.150486e+03\n",
       "cs                    2678  5.502139e+03\n",
       "da                    3542  5.023820e+03\n",
       "de                    3132  5.543252e+03\n",
       "es                    2709  3.969974e+03\n",
       "eu                     950          -inf\n",
       "fa                    1381  4.141576e+03\n",
       "fi                    2319  3.912588e+03\n",
       "fr                    4528  6.260868e+03\n",
       "he                    1149  3.234239e+03\n",
       "hi                    2470  8.541007e+03\n",
       "hr                    1883  3.378965e+03\n",
       "id                     846          -inf\n",
       "it                    3819  6.343649e+03\n",
       "no                    4596  6.609295e+03\n",
       "pl                    3012  6.186098e+03\n",
       "pt                    4838  7.715885e+03\n",
       "sl                    3129  6.347211e+03\n",
       "sv                    3910  5.230097e+03"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import warnings\n",
    "#warnings.filterwarnings('ignore', r\"\")\n",
    "\n",
    "p = Path(\".\")\n",
    "scores = defaultdict(list)\n",
    "sent_lens = []\n",
    "tree_scores = defaultdict(list)\n",
    "\n",
    "def softmax(sentence_matrix, temperature=1.0):\n",
    "    m_exp = np.exp(sentence_matrix/temperature)\n",
    "    return (m_exp.T / np.nansum(m_exp, axis=1)).T\n",
    "\n",
    "def l1_normalize(M):\n",
    "    return (M.T / np.nansum(M, axis=1)).T\n",
    "\n",
    "def eliminate_all_nan_vals(M_proj):\n",
    "    M_proj[np.isnan(M_proj)] = np.nanmin(M_proj)\n",
    "    \n",
    "#    with warnings.catch_warnings():\n",
    "#        warnings.simplefilter(\"ignore\")\n",
    "#        by_row = np.nanmax(M_proj, axis=1)\n",
    "#        all_nan_rows = np.isnan(by_row)\n",
    "#        M_proj[all_nan_rows] = np.nanmin(M_proj)\n",
    "\n",
    "def eval_projection(M_proj, name):\n",
    "    eliminate_all_nan_vals(M_proj)\n",
    "    pred_heads_from_all, tree_score = chu_liu_edmonds(M_proj)\n",
    "    scores[name].append(count_correct(pred_heads_from_all, gold_heads))\n",
    "    tree_scores[name].append(tree_score)\n",
    "\n",
    "def apply_softmax_per_row_per_lang(T_proj):\n",
    "    for lang in range(T_proj.shape[2]):\n",
    "        T_proj_lang = T_proj[:,:,lang]\n",
    "        T_proj[:,:,lang] = softmax(T_proj_lang, temperature=1)\n",
    "    \n",
    "token_count = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for file in p.glob(\"*.npz\"):\n",
    "    sent = np.load(str(file))\n",
    "    T_proj = sent['projection_tensor']\n",
    "    \n",
    "    #print(T_proj.shape[2])\n",
    "    #if T_proj.shape[2] < 15:\n",
    "    #    print(T_proj.shape[2])\n",
    "    #    continue\n",
    "    \n",
    "    source_langs = sent['source_languages']\n",
    "    \n",
    "    apply_softmax_per_row_per_lang(T_proj)\n",
    "    \n",
    "    gold_heads = np.concatenate([[-1], sent[\"heads\"]])\n",
    "    for lang in range(T_proj.shape[2]):\n",
    "        lang_name = source_langs[lang]\n",
    "        \n",
    "        T_proj_lang = T_proj[:,:,lang]\n",
    "        T_proj_lang = np.where(np.isnan(T_proj_lang), np.nanmin(T_proj_lang), T_proj_lang)\n",
    "        pred_heads, tree_score = chu_liu_edmonds(T_proj_lang)\n",
    "        \n",
    "        scores[lang_name].append(count_correct(pred_heads, gold_heads))\n",
    "        tree_scores[lang_name].append(tree_score)\n",
    "        \n",
    "        \n",
    "    # Aggregate measures\n",
    "    good_lang_ids = [i for i, lang_name in enumerate(source_langs)\n",
    "                     if lang_name in [\"fr\", \"de\", \"es\", \"sv\", \"no\", \"da\"]]\n",
    "    \n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        eval_projection(np.nansum(T_proj, axis=2), \"all_sum\")\n",
    "        eval_projection(np.nanmean(T_proj, axis=2), \"all_mean\")\n",
    "        eval_projection(np.nanmax(T_proj, axis=2), \"all_max\")\n",
    "\n",
    "        eval_projection(softmax(np.nansum(T_proj, axis=2)), \"all_sum_softmax\")\n",
    "        eval_projection(softmax(np.nanmean(T_proj, axis=2)), \"all_mean_softmax\")\n",
    "\n",
    "        eval_projection(l1_normalize(np.nansum(T_proj, axis=2)), \"all_sum_l1\")\n",
    "    \n",
    "    \n",
    "    sent_lens.append(len(pred_heads) - 1)\n",
    "    token_count += len(pred_heads) - 1\n",
    "\n",
    "aggregated_scores = {k: sum(vals) for k, vals in scores.items()}\n",
    "aggregated_tree_scores = {k: np.nansum(vals) for k, vals in tree_scores.items()}\n",
    "print(token_count)\n",
    "pd.DataFrame({\"tree_score\": pd.Series(aggregated_tree_scores), \n",
    "              \"accuracy\": pd.Series(aggregated_scores)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nansum([np.nan, np.nan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1097dac88>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAegAAAFVCAYAAAAkBHynAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEAENAICBCGgAAAz0fyk2hdfBXjLDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1097da550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "D = pd.DataFrame({\"accuracy\": np.array(scores[\"all_sum\"])  / np.array(sent_lens), \n",
    "                  \"tree_score\": np.array(tree_scores[\"all_sum\"]),\n",
    "                  \"norm_tree_score\": np.array(tree_scores[\"all_sum\"]) / np.array(sent_lens),\n",
    "                  \"sent_lens\": np.array(sent_lens)}\n",
    "                )\n",
    "\n",
    "#for i in range(11):\n",
    "#    print(D[D.accuracy > i / 10].sent_lens.mean())\n",
    "\n",
    "D.sent_lens.hist(bins=25)\n",
    "#D[D.sent_lens > 35].accuracy.mean()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  3,  0,  5,  3,  9,  9,  9,  3, 11,  9,  9,  9, 15, 16,  9, 19,\n",
       "       19, 16, 19, 15, 15, 25, 25, 16, 25, 28, 26, 15, 33, 32, 33, 15, 35,\n",
       "       33, 37, 35, 37, 15])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent['heads']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'M_norm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-d8ed125610ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mM_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM_norm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mchu_liu_edmonds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'M_norm' is not defined"
     ]
    }
   ],
   "source": [
    "x = np.zeros(M_norm.shape[1]) * np.nan\n",
    "M_norm = np.vstack([x, M_norm])\n",
    "chu_liu_edmonds(M_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
