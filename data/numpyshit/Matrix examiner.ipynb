{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from dependency_decoding import chu_liu_edmonds\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent = np.load(\"en.1.npz\")\n",
    "T_proj = sent['projection_tensor']\n",
    "source_langs = sent['source_languages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def count_correct(pred_heads, gold_heads):\n",
    "    assert len(pred_heads) == len(gold_heads)\n",
    "    # Do not count the root attachment at index 0 as correct\n",
    "    return sum(pred == gold for pred, gold in zip(pred_heads, gold_heads)) - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2   3   4   5   6   7   8   9   10  11\n",
       "0  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
       "1  NaN NaN NaN   1 NaN NaN NaN NaN NaN NaN NaN NaN\n",
       "2  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
       "3  NaN NaN NaN NaN NaN   1 NaN NaN NaN NaN NaN NaN\n",
       "4  NaN NaN NaN NaN NaN   1 NaN NaN NaN NaN NaN NaN\n",
       "5    1 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
       "6  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
       "7  NaN NaN NaN NaN NaN   1 NaN NaN NaN NaN NaN NaN\n",
       "8  NaN NaN NaN NaN NaN NaN NaN   1 NaN NaN NaN NaN\n",
       "9  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
       "10 NaN NaN NaN NaN NaN NaN NaN   1 NaN NaN NaN NaN\n",
       "11 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_proj_de = T_proj[:,:,4]\n",
    "\n",
    "\n",
    "\n",
    "D = pd.DataFrame(T_proj_de)\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmin(T_proj_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, 3, 0, 5, 5, 0, 0, 5, 7, 0, 7, 0] [-1  3  3  4  5  0  7  5  7 10  7  5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_proj_de[2] = np.nanmin(T_proj_de)\n",
    "T_proj_de[6] = np.nanmin(T_proj_de)\n",
    "T_proj_de[9] = np.nanmin(T_proj_de)\n",
    "\n",
    "pred_heads, tree_score = chu_liu_edmonds(T_proj_de)\n",
    "gold_heads = np.concatenate([[-1], sent[\"heads\"]])\n",
    "print(pred_heads, gold_heads)\n",
    "count_correct(pred_heads, gold_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2993\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>tree_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all_max</th>\n",
       "      <td>353</td>\n",
       "      <td>2083.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all_mean</th>\n",
       "      <td>314</td>\n",
       "      <td>2018.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all_mean_softmax</th>\n",
       "      <td>314</td>\n",
       "      <td>802.240906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all_sum</th>\n",
       "      <td>439</td>\n",
       "      <td>3603.919048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all_sum_l1</th>\n",
       "      <td>439</td>\n",
       "      <td>900.022063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all_sum_softmax</th>\n",
       "      <td>439</td>\n",
       "      <td>426.078566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>da</th>\n",
       "      <td>258</td>\n",
       "      <td>1748.783333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de</th>\n",
       "      <td>328</td>\n",
       "      <td>1648.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es</th>\n",
       "      <td>276</td>\n",
       "      <td>1644.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>224</td>\n",
       "      <td>1689.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>350</td>\n",
       "      <td>1724.497619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv</th>\n",
       "      <td>303</td>\n",
       "      <td>1674.433333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  accuracy   tree_score\n",
       "all_max                353  2083.666667\n",
       "all_mean               314  2018.708333\n",
       "all_mean_softmax       314   802.240906\n",
       "all_sum                439  3603.919048\n",
       "all_sum_l1             439   900.022063\n",
       "all_sum_softmax        439   426.078566\n",
       "da                     258  1748.783333\n",
       "de                     328  1648.619048\n",
       "es                     276  1644.200000\n",
       "fr                     224  1689.350000\n",
       "no                     350  1724.497619\n",
       "sv                     303  1674.433333"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import warnings\n",
    "#warnings.filterwarnings('ignore', r\"\")\n",
    "\n",
    "p = Path(\".\")\n",
    "scores = defaultdict(list)\n",
    "sent_lens = []\n",
    "tree_scores = defaultdict(list)\n",
    "\n",
    "def softmax(sentence_matrix, temperature=1.0):\n",
    "    m_exp = np.exp(sentence_matrix/temperature)\n",
    "    return (m_exp.T / np.nansum(m_exp, axis=1)).T\n",
    "\n",
    "def l1_normalize(M):\n",
    "    return (M.T / np.nansum(M, axis=1)).T\n",
    "\n",
    "def eliminate_all_nan_vals(M_proj):\n",
    "    M_proj[np.isnan(M_proj)] = np.nanmin(M_proj)\n",
    "    \n",
    "#    with warnings.catch_warnings():\n",
    "#        warnings.simplefilter(\"ignore\")\n",
    "#        by_row = np.nanmax(M_proj, axis=1)\n",
    "#        all_nan_rows = np.isnan(by_row)\n",
    "#        M_proj[all_nan_rows] = np.nanmin(M_proj)\n",
    "\n",
    "def eval_projection(M_proj, name):\n",
    "    eliminate_all_nan_vals(M_proj)\n",
    "    pred_heads_from_all, tree_score = chu_liu_edmonds(M_proj)\n",
    "    scores[name].append(count_correct(pred_heads_from_all, gold_heads))\n",
    "    tree_scores[name].append(tree_score)\n",
    "\n",
    "def apply_softmax_per_row_per_lang(T_proj):\n",
    "    for lang in range(T_proj.shape[2]):\n",
    "        T_proj_lang = T_proj[:,:,lang]\n",
    "        T_proj[:,:,lang] = softmax(T_proj_lang, temperature=1)\n",
    "    \n",
    "token_count = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for file in p.glob(\"*.npz\"):\n",
    "    sent = np.load(str(file))\n",
    "    T_proj = sent['projection_tensor']\n",
    "    \n",
    "    #print(T_proj.shape[2])\n",
    "    #if T_proj.shape[2] < 15:\n",
    "    #    print(T_proj.shape[2])\n",
    "    #    continue\n",
    "    \n",
    "    source_langs = sent['source_languages']\n",
    "    \n",
    "    apply_softmax_per_row_per_lang(T_proj)\n",
    "    \n",
    "    gold_heads = np.concatenate([[-1], sent[\"heads\"]])\n",
    "    for lang in range(T_proj.shape[2]):\n",
    "        lang_name = source_langs[lang]\n",
    "        \n",
    "        T_proj_lang = T_proj[:,:,lang]\n",
    "        T_proj_lang = np.where(np.isnan(T_proj_lang), np.nanmin(T_proj_lang), T_proj_lang)\n",
    "        pred_heads, tree_score = chu_liu_edmonds(T_proj_lang)\n",
    "        \n",
    "        scores[lang_name].append(count_correct(pred_heads, gold_heads))\n",
    "        tree_scores[lang_name].append(tree_score)\n",
    "        \n",
    "        \n",
    "    # Aggregate measures\n",
    "    good_lang_ids = [i for i, lang_name in enumerate(source_langs)\n",
    "                     if lang_name in [\"fr\", \"de\", \"es\", \"sv\", \"no\", \"da\"]]\n",
    "    \n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        eval_projection(np.nansum(T_proj, axis=2), \"all_sum\")\n",
    "        eval_projection(np.nanmean(T_proj, axis=2), \"all_mean\")\n",
    "        eval_projection(np.nanmax(T_proj, axis=2), \"all_max\")\n",
    "\n",
    "        eval_projection(softmax(np.nansum(T_proj, axis=2)), \"all_sum_softmax\")\n",
    "        eval_projection(softmax(np.nanmean(T_proj, axis=2)), \"all_mean_softmax\")\n",
    "\n",
    "        eval_projection(l1_normalize(np.nansum(T_proj, axis=2)), \"all_sum_l1\")\n",
    "    \n",
    "    \n",
    "    sent_lens.append(len(pred_heads) - 1)\n",
    "    token_count += len(pred_heads) - 1\n",
    "\n",
    "aggregated_scores = {k: sum(vals) for k, vals in scores.items()}\n",
    "aggregated_tree_scores = {k: np.nansum(vals) for k, vals in tree_scores.items()}\n",
    "print(token_count)\n",
    "pd.DataFrame({\"tree_score\": pd.Series(aggregated_tree_scores), \n",
    "              \"accuracy\": pd.Series(aggregated_scores)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nansum([np.nan, np.nan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10984fc18>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAECCAYAAADjBlzIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10986c390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "D = pd.DataFrame({\"accuracy\": np.array(scores[\"all_sum\"])  / np.array(sent_lens), \n",
    "                  \"tree_score\": np.array(tree_scores[\"all_sum\"]),\n",
    "                  \"norm_tree_score\": np.array(tree_scores[\"all_sum\"]) / np.array(sent_lens),\n",
    "                  \"sent_lens\": np.array(sent_lens)}\n",
    "                )\n",
    "\n",
    "#for i in range(11):\n",
    "#    print(D[D.accuracy > i / 10].sent_lens.mean())\n",
    "\n",
    "D.sent_lens.hist(bins=25)\n",
    "#D[D.sent_lens > 35].accuracy.mean()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  3,  0,  7,  3,  7,  3,  7, 10,  3, 13, 13, 10, 15, 10, 15, 15,\n",
       "       19, 15, 23, 23, 23, 19,  3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent['heads']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'M_norm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-d8ed125610ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mM_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM_norm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mchu_liu_edmonds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'M_norm' is not defined"
     ]
    }
   ],
   "source": [
    "x = np.zeros(M_norm.shape[1]) * np.nan\n",
    "M_norm = np.vstack([x, M_norm])\n",
    "chu_liu_edmonds(M_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
